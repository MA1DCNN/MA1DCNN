{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c1501f/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import activations\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import optimizers\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras import utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.01\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(session )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_processing(data):\n",
    "    \n",
    "    data_mean = data.mean()\n",
    "    data_var = data.var()\n",
    "    \n",
    "    data = data - data_mean\n",
    "    data = data / data_var\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 196\n",
    "test_batch = 196\n",
    "\n",
    "train_num = 142420\n",
    "test_num = 45668\n",
    "\n",
    "cross = \"cross_1\"\n",
    "\n",
    "snr_str = \"-6_detail_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_train_data():\n",
    "    \n",
    "    train_data = np.zeros((train_batch, 2048, 1), dtype = np.float32)\n",
    "\n",
    "    \n",
    "    train_lab = np.zeros((train_batch))\n",
    "    flag = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        list = random.sample(range(train_num), train_num)\n",
    "        \n",
    "        for id in list:\n",
    "            \n",
    "            num_id = str(id)\n",
    "            \n",
    "            line_train_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/train_data/\" + num_id + \"_train.npy\")\n",
    "            line_train_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/train_lab/\" + num_id + \"_lab.npy\")\n",
    "            \n",
    "            line_train_data = normalization_processing(line_train_data)\n",
    "\n",
    "            train_data[flag , :, 0] = line_train_data\n",
    "\n",
    "            train_lab[flag] = line_train_lab\n",
    "            \n",
    "            flag += 1\n",
    "            \n",
    "            if flag >= train_batch:\n",
    "                \n",
    "                train_hot_lab = to_categorical(train_lab, num_classes=12)\n",
    "                \n",
    "                yield [train_data], [train_hot_lab]\n",
    "                \n",
    "                flag = 0\n",
    "                train_data = np.zeros((train_batch, 2048, 1), dtype = np.float32)\n",
    "                \n",
    "                train_lab = np.zeros((train_batch))\n",
    "\n",
    "        \n",
    "def generate_1d_test_data():\n",
    "    \n",
    "    test_data = np.zeros((test_batch, 2048, 1), dtype = np.float32)\n",
    "    \n",
    "    test_lab = np.zeros((test_batch))\n",
    "    flag = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        list = random.sample(range(test_num), test_num)\n",
    "        \n",
    "        for id in list:\n",
    "            \n",
    "            num_id = str(id)\n",
    "            \n",
    "            line_test_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_data/\" + num_id + \"_test.npy\")\n",
    "            line_test_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_lab/\" + num_id + \"_lab.npy\")\n",
    "            \n",
    "            line_test_data = normalization_processing(line_test_data)\n",
    "            \n",
    "            test_data[flag , :, 0] = line_test_data\n",
    "            \n",
    "            test_lab[flag] = line_test_lab\n",
    "            \n",
    "            flag += 1\n",
    "            \n",
    "            if flag >= train_batch:\n",
    "                \n",
    "                test_hot_lab = to_categorical(test_lab, num_classes=12)\n",
    "                \n",
    "                yield [test_data], [test_hot_lab]\n",
    "                \n",
    "                flag = 0\n",
    "                test_data = np.zeros((test_batch, 2048, 1), dtype = np.float32)\n",
    "          \n",
    "                test_lab = np.zeros((test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_test_data():\n",
    "    \n",
    "    test_data = np.zeros((test_num, 2048, 1), dtype = np.float32)\n",
    "    \n",
    "    test_lab = np.zeros((test_num))\n",
    "    \n",
    "    flag = 0\n",
    "    list = random.sample(range(test_num), test_num)\n",
    "    \n",
    "    for id in list:\n",
    "        \n",
    "        num_id = str(id)\n",
    "        \n",
    "        line_test_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_data/\" + num_id + \"_test.npy\")\n",
    "        line_test_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_lab/\" + num_id + \"_lab.npy\")\n",
    "        \n",
    "        line_test_data = normalization_processing(line_test_data)\n",
    "\n",
    "        test_data[flag , :, 0] = line_test_data\n",
    "        \n",
    "        test_lab[flag] = line_test_lab\n",
    "        \n",
    "        flag += 1\n",
    "        \n",
    "    test_hot_lab = to_categorical(test_lab, num_classes=12)\n",
    "    \n",
    "    return test_data, test_hot_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1D_bn(x, filters, kernel_size, strides):\n",
    "    \n",
    "    C1 = Conv1D(filters, kernel_size, strides=strides, padding='same')(x) \n",
    "    C1 = Activation('relu')(C1)\n",
    "    \n",
    "    return C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_CAM(in_x, nb_filter):\n",
    "\n",
    "    c = GlobalAveragePooling1D()(in_x)\n",
    "    c = Reshape((1, nb_filter))(c)\n",
    "    \n",
    "    c = Conv1D(int(nb_filter/2), 1, padding='same')(c) \n",
    "    #c = BatchNormalization()(c)\n",
    "    c = Activation('relu')(c)\n",
    "    \n",
    "    c = Conv1D(nb_filter, 1, padding='same')(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = Activation('sigmoid')(c)\n",
    "    \n",
    "    x = multiply([in_x, c])\n",
    "    out = add([in_x, x])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def A_EAM(in_x, nb_filter, kernel_size):\n",
    "        \n",
    "    t = Conv1D(1, 1, padding='same')(in_x)\n",
    "    t = BatchNormalization()(t)\n",
    "    t = Activation('sigmoid')(t)\n",
    "    \n",
    "    x = Conv1D(nb_filter, kernel_size, padding='same')(in_x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = multiply([x, t])\n",
    "    out = add([in_x, x])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def A_JAM(in_x, nb_filter, kernel_size):\n",
    "    \n",
    "    cx = A_CAM(in_x, nb_filter)\n",
    "    tx = A_tSE(cx, nb_filter, kernel_size)\n",
    "    \n",
    "    return tx   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MA1DCNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "    cnn = A_EAM(cnn, 32, 32)\n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "    cnn = A_EAM(cnn, 32, 16)\n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 9)\n",
    "    cnn = A_CAM(cnn, 64)    \n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 6)\n",
    "    cnn = A_CAM(cnn, 64)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    cnn = A_EAM(cnn, 128, 3)\n",
    "    cnn = A_CAM(cnn, 128)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACAM_CNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "    cnn = A_CAM(cnn, 32)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_CAM(cnn, 64)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_CAM(cnn, 64)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    cnn = A_CAM(cnn, 128)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def AEAM_CNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "    cnn = A_EAM(cnn, 32, 32)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "    cnn = A_EAM(cnn, 32, 16)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 9)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    cnn = A_EAM(cnn, 64, 6)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    cnn = A_EAM(cnn, 128, 3)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_CNN():\n",
    "    \n",
    "    input_signal = Input(shape=(2048,1))\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 32, activation='relu', padding='same', strides=1)(input_signal)\n",
    "\n",
    "    cnn = Conv1D(32, kernel_size = 16, activation='relu', padding='same', strides=2)(cnn)   \n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 9, activation='relu', padding='same', strides=2)(cnn)\n",
    "\n",
    "    cnn = Conv1D(64, kernel_size = 6, activation='relu', padding='same', strides=2)(cnn)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    cnn = Conv1D(128, kernel_size = 3, activation='relu', padding='same', strides=4)(cnn)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(cnn)\n",
    "    \n",
    "    output = Dense(12, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_signal, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AJAM_WDCNN():\n",
    "    \n",
    "    input_signal = Input((2048, 1))\n",
    "    \n",
    "    x = Conv1D(16, 64, strides=16, padding='same')(input_signal)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 16, 64)\n",
    "    x = A_CAM(x, 16)   \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(32, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 32, 3)\n",
    "    x = A_CAM(x, 32)      \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 64, 3)\n",
    "    x = A_CAM(x, 64)      \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = A_EAM(x, 64, 3)\n",
    "    x = A_CAM(x, 64)    \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = MaxPooling1D(2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(100,  activation='relu')(x)\n",
    "    \n",
    "    x = Dense(12,  activation='softmax')(x)\n",
    "    \n",
    "    model = Model(input_signal, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.adam(lr = 0.0001)\n",
    "\n",
    "model = MA1DCNN()\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyCbk(Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model_to_save = model\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        print('save model----model_at_epoch_%d.h5' % epoch)\n",
    "        self.model_to_save.save('model_1/model_%d.h5' % epoch)\n",
    "        \n",
    "cbk = MyCbk(model)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.90, patience=5, verbose=0, mode='auto', cooldown=0, min_lr=0.0000001)\n",
    "\n",
    "results = model.fit_generator(generate_1d_train_data(), steps_per_epoch = train_num/train_batch, epochs = 100, validation_data = generate_1d_test_data(), validation_steps = test_num/test_batch, verbose=1, callbacks=[cbk, reduceLR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data, all_test_lab = get_all_test_data()\n",
    "\n",
    "\n",
    "Accuracy_list = np.zeros((100))\n",
    "Recall_list = np.zeros((100))\n",
    "Precision_list = np.zeros((100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in range(100):\n",
    "    \n",
    "    str_id = str(model_id)\n",
    "    \n",
    "    model =  load_model('model_1/model_'+ str_id +'.h5') \n",
    "    \n",
    "    all_score = 0\n",
    "    \n",
    "    range_num = int(test_num/test_batch)\n",
    "    \n",
    "    input_lab = []\n",
    "    output_lab = []\n",
    "    \n",
    "    for num_id in range(range_num):\n",
    "        \n",
    "        test_data = all_test_data[num_id*test_batch:test_batch+num_id*test_batch,:,:]\n",
    "        \n",
    "        test_lab = all_test_lab[num_id*test_batch:test_batch+num_id*test_batch,:]\n",
    "    \n",
    "        pre_lab = model.predict(test_data, batch_size=test_batch, verbose=0)\n",
    "             \n",
    "        input_lab.extend(test_lab)\n",
    "        output_lab.extend(pre_lab)\n",
    "\n",
    "    labels_test = np.argmax(input_lab,axis=1)  \n",
    "    labels_pred = np.argmax(output_lab,axis=1)\n",
    "          \n",
    "    Accuracy = accuracy_score(labels_test, labels_pred)\n",
    "    Recall = recall_score(labels_test, labels_pred, average='macro')\n",
    "    #F1_score = f1_score(labels_test, labels_pred, average='macro')\n",
    "    Precision = precision_score(labels_test, labels_pred, average='macro')\n",
    "    \n",
    "    Accuracy_list[model_id] = Accuracy\n",
    "    Recall_list[model_id] = Recall\n",
    "    Precision_list[model_id] = Precision\n",
    "    \n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Accuracy_str = \"[\"\n",
    "Recall_str = \"[\"\n",
    "Precision_str = \"[\"\n",
    "\n",
    "for id in range(100):\n",
    "    \n",
    "    Accuracy_num = round(Accuracy_list[id], 5)\n",
    "    Recall_num = round(Recall_list[id], 5)\n",
    "    Precision_num = round(Precision_list[id], 5)\n",
    "\n",
    "    Accuracy_str = Accuracy_str + str(Accuracy_num)\n",
    "    Recall_str = Recall_str + str(Recall_num)\n",
    "    Precision_str = Precision_str + str(Precision_num)\n",
    "    \n",
    "    if id == 99:\n",
    "        Accuracy_str = Accuracy_str + \"]\"\n",
    "        Recall_str = Recall_str + \"]\"\n",
    "        Precision_str = Precision_str + \"]\"\n",
    "    else:\n",
    "        Accuracy_str = Accuracy_str + \", \"\n",
    "        Recall_str = Recall_str + \", \"\n",
    "        Precision_str = Precision_str + \", \"\n",
    "\n",
    "print(\"Accuracy_score:\")\n",
    "print(Accuracy_str)\n",
    "print(\"Recall_score:\")\n",
    "print(Recall_str)\n",
    "print(\"Precision_score:\")\n",
    "print(Precision_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_num = 11172\n",
    "test_batch = 133\n",
    "class_num = \"0\"\n",
    "\n",
    "test_num = 3724\n",
    "test_batch = 133\n",
    "class_num = \"1\"\n",
    "\n",
    "test_num = 4704\n",
    "test_batch = 147\n",
    "class_num = \"2\"\n",
    "\n",
    "test_num = 2058\n",
    "test_batch = 147\n",
    "class_num = \"3\"\n",
    "\n",
    "test_num = 1960\n",
    "test_batch = 196\n",
    "class_num = \"4\"\n",
    "\n",
    "test_num = 3920\n",
    "test_batch = 245\n",
    "class_num = \"5\"\n",
    "\n",
    "test_num = 3430\n",
    "test_batch = 343\n",
    "class_num = \"6\"\n",
    "\n",
    "test_num = 3136\n",
    "test_batch = 196\n",
    "class_num = \"7\"\n",
    "\n",
    "test_num = 3234\n",
    "test_batch = 231\n",
    "class_num = \"8\"\n",
    "\n",
    "test_num = 3528\n",
    "test_batch = 147\n",
    "class_num = \"9\"\n",
    "\n",
    "test_num = 3920\n",
    "test_batch = 245\n",
    "class_num = \"10\"\n",
    "\n",
    "test_num = 882\n",
    "test_batch = 147\n",
    "class_num = \"11\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 2058\n",
    "test_batch = 147\n",
    "class_num = \"3\"\n",
    "\n",
    "\n",
    "def get_0_test_data():\n",
    "    \n",
    "    test_data = np.zeros((test_num, 2048, 1), dtype = np.float32)\n",
    "    \n",
    "    test_lab = np.zeros((test_num))\n",
    "    \n",
    "    flag = 0\n",
    "    list = random.sample(range(test_num), test_num)\n",
    "    \n",
    "    for id in list:\n",
    "        \n",
    "        num_id = str(id)\n",
    "        \n",
    "        line_test_data = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_detail/\"+class_num+\"/\" + num_id + \"_test.npy\")\n",
    "        line_test_lab = np.load(\"../../H-S_data/noise_data/\"+cross+\"/\"+snr_str+\"/test_lab_detail/\"+class_num+\"/\" + num_id + \"_lab.npy\")\n",
    "        \n",
    "        line_test_data = normalization_processing(line_test_data)\n",
    "\n",
    "        test_data[flag , :, 0] = line_test_data\n",
    "        \n",
    "        test_lab[flag] = line_test_lab\n",
    "        \n",
    "        flag += 1\n",
    "        \n",
    "    test_hot_lab = to_categorical(test_lab, num_classes=12)\n",
    "    \n",
    "    return test_data, test_hot_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data, all_test_lab = get_0_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model =  load_model('model_1/model_94.h5') \n",
    "\n",
    "all_score = 0\n",
    "\n",
    "range_num = int(test_num/test_batch)\n",
    "\n",
    "input_lab = []\n",
    "output_lab = []\n",
    "\n",
    "for num_id in range(range_num):\n",
    "\n",
    "    test_data = all_test_data[num_id*test_batch:test_batch+num_id*test_batch,:,:]\n",
    "\n",
    "    test_lab = all_test_lab[num_id*test_batch:test_batch+num_id*test_batch,:]\n",
    "\n",
    "    pre_lab = model.predict(test_data, batch_size=test_batch, verbose=0)\n",
    "\n",
    "    input_lab.extend(test_lab)\n",
    "    output_lab.extend(pre_lab)\n",
    "\n",
    "labels_test = np.argmax(input_lab,axis=1)  \n",
    "labels_pred = np.argmax(output_lab,axis=1)\n",
    "\n",
    "\n",
    "print(labels_test.shape)\n",
    "\n",
    "count_0 = np.sum(labels_pred == 0)\n",
    "count_1 = np.sum(labels_pred == 1)\n",
    "count_2 = np.sum(labels_pred == 2)\n",
    "count_3 = np.sum(labels_pred == 3)\n",
    "count_4 = np.sum(labels_pred == 4)\n",
    "count_5 = np.sum(labels_pred == 5)\n",
    "count_6 = np.sum(labels_pred == 6)\n",
    "count_7 = np.sum(labels_pred == 7)\n",
    "count_8 = np.sum(labels_pred == 8)\n",
    "count_9 = np.sum(labels_pred == 9)\n",
    "count_10 = np.sum(labels_pred == 10)\n",
    "count_11 = np.sum(labels_pred == 11)\n",
    "\n",
    "count_all_pre = count_0+count_1+count_2+count_3+count_4+count_5+count_6+count_7+count_8+count_9+count_10+count_11\n",
    "\n",
    "print(\"pre-c0: \"+str(count_0)+\", 百分比：\"+str(count_0/count_all_pre*100))\n",
    "print(\"pre-c1: \"+str(count_1)+\", 百分比：\"+str(count_1/count_all_pre*100))\n",
    "print(\"pre-c2: \"+str(count_2)+\", 百分比：\"+str(count_2/count_all_pre*100))\n",
    "print(\"pre-c3: \"+str(count_3)+\", 百分比：\"+str(count_3/count_all_pre*100))\n",
    "print(\"pre-c4: \"+str(count_4)+\", 百分比：\"+str(count_4/count_all_pre*100))\n",
    "print(\"pre-c5: \"+str(count_5)+\", 百分比：\"+str(count_5/count_all_pre*100))\n",
    "print(\"pre-c6: \"+str(count_6)+\", 百分比：\"+str(count_6/count_all_pre*100))\n",
    "print(\"pre-c7: \"+str(count_7)+\", 百分比：\"+str(count_7/count_all_pre*100))\n",
    "print(\"pre-c8: \"+str(count_8)+\", 百分比：\"+str(count_8/count_all_pre*100))\n",
    "print(\"pre-c9: \"+str(count_9)+\", 百分比：\"+str(count_9/count_all_pre*100))\n",
    "print(\"pre-c10: \"+str(count_10)+\", 百分比：\"+str(count_10/count_all_pre*100))\n",
    "print(\"pre-c11: \"+str(count_11)+\", 百分比：\"+str(count_11/count_all_pre*100))\n",
    "print(\"Pre-all: \"+str(count_all_pre))\n",
    "\n",
    "\n",
    "Accuracy = accuracy_score(labels_test, labels_pred)\n",
    "\n",
    "\n",
    "Accuracy_list[model_id] = Accuracy\n",
    "\n",
    "\n",
    "print(\"第\"+ str(model_id) + \"个模型的结果：\")\n",
    "print(Accuracy)\n",
    "\n",
    "\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
