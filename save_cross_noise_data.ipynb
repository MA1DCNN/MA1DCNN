{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir0 = '../npy_data/1_normal_1'\n",
    "rootdir00 = '../npy_data/2_normal_2'\n",
    "rootdir1 = '../npy_data/3_fault_2107'\n",
    "rootdir2 = '../npy_data/4_fault_130'\n",
    "rootdir3 = '../npy_data/5_fault_1859'\n",
    "rootdir4 = '../npy_data/6_fault_1425'\n",
    "rootdir5 = '../npy_data/7_fault_2117'\n",
    "rootdir6 = '../npy_data/8_fault_1430'\n",
    "rootdir7 = '../npy_data/9_fault_1822'\n",
    "rootdir8 = '../npy_data/10_fault_2067'\n",
    "rootdir9 = '../npy_data/11_fault_2120'\n",
    "rootdir10 = '../npy_data/12_fault_2126'\n",
    "rootdir11 = '../npy_data/13_fault_1950'\n",
    "\n",
    "list_0 = os.listdir(rootdir0) #列出文件夹下所有的目录与文件\n",
    "list_00 = os.listdir(rootdir00)\n",
    "list_1 = os.listdir(rootdir1)\n",
    "list_2 = os.listdir(rootdir2)\n",
    "list_3 = os.listdir(rootdir3)\n",
    "list_4 = os.listdir(rootdir4)\n",
    "list_5 = os.listdir(rootdir5)\n",
    "list_6 = os.listdir(rootdir6)\n",
    "list_7 = os.listdir(rootdir7)\n",
    "list_8 = os.listdir(rootdir8)\n",
    "list_9 = os.listdir(rootdir9)\n",
    "list_10 = os.listdir(rootdir10)\n",
    "list_11 = os.listdir(rootdir11)\n",
    "\n",
    "lab0 = np.array([0])\n",
    "lab1 = np.array([1])\n",
    "lab2 = np.array([2])\n",
    "lab3 = np.array([3])\n",
    "lab4 = np.array([4])\n",
    "lab5 = np.array([5])\n",
    "lab6 = np.array([6])\n",
    "lab7 = np.array([7])\n",
    "lab8 = np.array([8])\n",
    "lab9 = np.array([9])\n",
    "lab10 = np.array([10])\n",
    "lab11 = np.array([11])\n",
    "\n",
    "num_train = 0 \n",
    "num_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_num = 6\n",
    "snr_str = \"6_detail_db\"\n",
    "cross_num = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wgn(x, snr):\n",
    "    \n",
    "    snr = 10**(snr/10.0)\n",
    "    xpower = np.sum(x**2)/len(x)\n",
    "    npower = xpower / snr\n",
    "    \n",
    "    return np.random.randn(len(x)) * np.sqrt(npower)\n",
    "\n",
    "\n",
    "def add_noise(data):\n",
    "    \n",
    "    rand_data = wgn(data, snr_num)\n",
    "    \n",
    "    data = data + rand_data\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        train_data1 = data_npy[0:28672]\\n        train_data2 = data_npy[43008:]\\n        train_data = np.concatenate((train_data1,train_data2))\\n        test_data = data_npy[28672:43008]\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "        train_data1 = data_npy[0:28672]\n",
    "        train_data2 = data_npy[43008:]\n",
    "        train_data = np.concatenate((train_data1,train_data2))\n",
    "        test_data = data_npy[28672:43008]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_0 in range(0,len(list_0)):\n",
    "    \n",
    "    path = os.path.join(rootdir0,list_0[id_0])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        #train_data1 = data_npy[0:14336]\n",
    "        #train_data2 = data_npy[28672:]\n",
    "        #train_data = np.concatenate((train_data1,train_data2))\n",
    "        #test_data = data_npy[14336:28672]\n",
    "\n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab0)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab0)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/0/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/0/\"+ str_detail_num + \"_lab.npy\", lab0)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1\n",
    "                    \n",
    "\n",
    "for id_00 in range(0,len(list_00)):\n",
    "    \n",
    "    path = os.path.join(rootdir00,list_00[id_00])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab0)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab0)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/0/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/0/\"+ str_detail_num + \"_lab.npy\", lab0)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_1 in range(0,len(list_1)):\n",
    "    \n",
    "    path = os.path.join(rootdir1,list_1[id_1])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab1)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab1)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/1/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/1/\"+ str_detail_num + \"_lab.npy\", lab1)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_2 in range(0,len(list_2)):\n",
    "    \n",
    "    path = os.path.join(rootdir2,list_2[id_2])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab2)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab2)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/2/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/2/\"+ str_detail_num + \"_lab.npy\", lab2)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_3 in range(0,len(list_3)):\n",
    "    \n",
    "    path = os.path.join(rootdir3,list_3[id_3])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab3)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab3)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/3/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/3/\"+ str_detail_num + \"_lab.npy\", lab3)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_4 in range(0,len(list_4)):\n",
    "    \n",
    "    path = os.path.join(rootdir4,list_4[id_4])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab4)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab4)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/4/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/4/\"+ str_detail_num + \"_lab.npy\", lab4)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_5 in range(0,len(list_5)):\n",
    "    \n",
    "    path = os.path.join(rootdir5,list_5[id_5])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab5)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab5)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/5/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/5/\"+ str_detail_num + \"_lab.npy\", lab5)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_6 in range(0,len(list_6)):\n",
    "    \n",
    "    path = os.path.join(rootdir6,list_6[id_6])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab6)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab6)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/6/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/6/\"+ str_detail_num + \"_lab.npy\", lab6)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_7 in range(0,len(list_7)):\n",
    "    \n",
    "    path = os.path.join(rootdir7,list_7[id_7])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab7)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab7)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/7/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/7/\"+ str_detail_num + \"_lab.npy\", lab7)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_8 in range(0,len(list_8)):\n",
    "    \n",
    "    path = os.path.join(rootdir8,list_8[id_8])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab8)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab8)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/8/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/8/\"+ str_detail_num + \"_lab.npy\", lab8)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_9 in range(0,len(list_9)):\n",
    "    \n",
    "    path = os.path.join(rootdir9,list_9[id_9])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab9)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab9)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/9/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/9/\"+ str_detail_num + \"_lab.npy\", lab9)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_10 in range(0,len(list_10)):\n",
    "    \n",
    "    path = os.path.join(rootdir10,list_10[id_10])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab10)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab10)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/10/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/10/\"+ str_detail_num + \"_lab.npy\", lab10)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_num = 0\n",
    "\n",
    "for id_11 in range(0,len(list_11)):\n",
    "    \n",
    "    path = os.path.join(rootdir11,list_11[id_11])\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        data_npy = np.load(path)\n",
    "        \n",
    "        data_npy = add_noise(data_npy)\n",
    "        \n",
    "        train_data = data_npy[14336:]\n",
    "        test_data = data_npy[0:14336]\n",
    "        \n",
    "        train_len = (len(train_data)/1024-2)*4 + 1\n",
    "        test_len = (len(test_data)/1024-2)*4 + 1\n",
    "        \n",
    "        train_len = int(train_len)\n",
    "        test_len = int(test_len)\n",
    "        \n",
    "        for sub_id in range(0, train_len):\n",
    "            \n",
    "            sub_train_data = train_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_train = str(num_train)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_data/\"+ str_num_train + \"_train.npy\", sub_train_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/train_lab/\"+ str_num_train + \"_lab.npy\", lab11)    \n",
    "            \n",
    "            num_train += 1\n",
    "        \n",
    "        for sub_id in range(0, test_len):\n",
    "            \n",
    "            sub_test_data = test_data[sub_id*256:sub_id*256+2048]\n",
    "            \n",
    "            str_num_test = str(num_test)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_data/\"+ str_num_test + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab/\"+ str_num_test + \"_lab.npy\", lab11)    \n",
    "            \n",
    "            str_detail_num = str(detail_num)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_detail/11/\"+ str_detail_num + \"_test.npy\", sub_test_data)\n",
    "            np.save(\"../H-S_data/noise_data/cross_\"+cross_num+\"/\"+snr_str+\"/test_lab_detail/11/\"+ str_detail_num + \"_lab.npy\", lab11)       \n",
    "            detail_num += 1\n",
    "            \n",
    "            num_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
